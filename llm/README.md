### LLM Module

This module handles the actual dialogue generation, task completion and decision making. If you're new to this, think of it as a ChatGPT that runs locally.

We start by using a tiny SOTA model produced by Microsoft. It's called Phi 3 and should run on your Macbook. Can be expanded to use more capable models. Phi 3 provides a good base for most macbooks using an "M" class chip with more than 4GB unified memory (every model to my knowledge). Upgrading to Mistral or LLama 3 would also be a good idea if you have a more powerful macbook.
